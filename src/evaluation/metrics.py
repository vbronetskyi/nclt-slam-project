"""SLAM and place recognition evaluation metrics.

Provides standard evaluation metrics for visual/LiDAR SLAM pipelines and
place recognition systems, including Absolute Trajectory Error (ATE),
Relative Pose Error (RPE), Recall@K, and precision-recall analysis for
loop closure detection.

Depends on:
    numpy, scipy
"""

from __future__ import annotations

import logging
from typing import Any

import numpy as np
from scipy.spatial.distance import cdist
from scipy.spatial.transform import Rotation

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------------
# Low-level helpers
# ---------------------------------------------------------------------------


def pose_error(
    pose_est: np.ndarray,
    pose_gt: np.ndarray,
) -> tuple[float, float]:
    """Compute translation and rotation error between two SE3 poses.

    Args:
        pose_est: Estimated pose as a (4, 4) homogeneous transformation matrix.
        pose_gt: Ground-truth pose as a (4, 4) homogeneous transformation matrix.

    Returns:
        A tuple ``(trans_err, rot_err)`` where *trans_err* is the Euclidean
        translation error in meters and *rot_err* is the rotation error in
        degrees (angle of the residual rotation).

    Raises:
        ValueError: If either input does not have shape (4, 4).
    """
    pose_est = np.asarray(pose_est, dtype=np.float64)
    pose_gt = np.asarray(pose_gt, dtype=np.float64)

    if pose_est.shape != (4, 4):
        raise ValueError(
            f"pose_est must have shape (4, 4), got {pose_est.shape}"
        )
    if pose_gt.shape != (4, 4):
        raise ValueError(
            f"pose_gt must have shape (4, 4), got {pose_gt.shape}"
        )

    # Relative transform: error = gt^{-1} @ est
    R_est = pose_est[:3, :3]
    t_est = pose_est[:3, 3]
    R_gt = pose_gt[:3, :3]
    t_gt = pose_gt[:3, 3]

    # Translation error
    trans_err = float(np.linalg.norm(t_est - t_gt))

    # Rotation error – angle of R_gt^T @ R_est
    R_diff = R_gt.T @ R_est
    # Clamp the trace to valid acos range [-1, 3] -> cos(angle) in [-1, 1]
    cos_angle = (np.trace(R_diff) - 1.0) / 2.0
    cos_angle = np.clip(cos_angle, -1.0, 1.0)
    rot_err_rad = float(np.arccos(cos_angle))
    rot_err_deg = float(np.degrees(rot_err_rad))

    return trans_err, rot_err_deg


# ---------------------------------------------------------------------------
# Umeyama alignment
# ---------------------------------------------------------------------------


def umeyama_alignment(
    estimated: np.ndarray,
    ground_truth: np.ndarray,
) -> tuple[np.ndarray, np.ndarray, float]:
    """Umeyama alignment of two point sets (with scale).

    Finds rotation *R*, translation *t*, and scale *s* that minimise::

        sum_i || ground_truth_i - (s * R @ estimated_i + t) ||^2

    Reference:
        S. Umeyama, "Least-squares estimation of transformation parameters
        between two point patterns," IEEE TPAMI 13(4), 1991.

    Args:
        estimated: Estimated positions, shape (N, 3).
        ground_truth: Ground-truth positions, shape (N, 3).

    Returns:
        A tuple ``(R, t, s)`` where *R* is a (3, 3) rotation matrix,
        *t* is a (3,) translation vector, and *s* is a positive scalar scale
        factor.

    Raises:
        ValueError: If inputs have incompatible shapes or fewer than 3 points.
    """
    estimated = np.asarray(estimated, dtype=np.float64)
    ground_truth = np.asarray(ground_truth, dtype=np.float64)

    if estimated.ndim != 2 or estimated.shape[1] != 3:
        raise ValueError(
            f"estimated must have shape (N, 3), got {estimated.shape}"
        )
    if ground_truth.ndim != 2 or ground_truth.shape[1] != 3:
        raise ValueError(
            f"ground_truth must have shape (N, 3), got {ground_truth.shape}"
        )
    if estimated.shape[0] != ground_truth.shape[0]:
        raise ValueError(
            f"Point set sizes differ: estimated has {estimated.shape[0]} "
            f"points, ground_truth has {ground_truth.shape[0]} points"
        )

    n = estimated.shape[0]
    if n < 3:
        raise ValueError(
            f"At least 3 points are required for Umeyama alignment, got {n}"
        )

    # Centroids
    mu_est = estimated.mean(axis=0)
    mu_gt = ground_truth.mean(axis=0)

    # Centred coordinates
    est_c = estimated - mu_est
    gt_c = ground_truth - mu_gt

    # Variances
    sigma_est_sq = np.mean(np.sum(est_c ** 2, axis=1))

    # Cross-covariance matrix
    sigma = (gt_c.T @ est_c) / n

    U, D, Vt = np.linalg.svd(sigma)

    # Construct S matrix to ensure proper rotation (det = +1)
    S = np.eye(3)
    if np.linalg.det(U) * np.linalg.det(Vt) < 0:
        S[2, 2] = -1

    # Rotation
    R = U @ S @ Vt

    # Scale
    s = float(np.trace(np.diag(D) @ S) / sigma_est_sq)

    # Translation
    t = mu_gt - s * R @ mu_est

    return R, t, s


# ---------------------------------------------------------------------------
# Absolute Trajectory Error (ATE)
# ---------------------------------------------------------------------------


def compute_ate(
    estimated: np.ndarray,
    ground_truth: np.ndarray,
) -> dict[str, float]:
    """Compute the Absolute Trajectory Error (ATE) after Umeyama alignment.

    The estimated trajectory is first aligned to the ground-truth trajectory
    using :func:`umeyama_alignment` (solving for rotation, translation, and
    scale).  ATE is then computed as the Euclidean distance between
    corresponding aligned positions.

    Args:
        estimated: Estimated poses, shape (N, 4, 4).  Each entry is a
            homogeneous SE3 transformation matrix.
        ground_truth: Ground-truth poses, shape (N, 4, 4).

    Returns:
        A dict with keys ``"rmse"``, ``"mean"``, ``"median"``, ``"std"``,
        and ``"max"`` – all in the same unit as the input translations
        (typically meters).

    Raises:
        ValueError: If inputs are empty, have mismatched lengths, or do not
            have the expected ``(N, 4, 4)`` shape.
    """
    estimated = np.asarray(estimated, dtype=np.float64)
    ground_truth = np.asarray(ground_truth, dtype=np.float64)

    # --- input validation ---------------------------------------------------
    if estimated.size == 0 or ground_truth.size == 0:
        raise ValueError("Input pose arrays must not be empty.")

    if estimated.ndim != 3 or estimated.shape[1:] != (4, 4):
        raise ValueError(
            f"estimated must have shape (N, 4, 4), got {estimated.shape}"
        )
    if ground_truth.ndim != 3 or ground_truth.shape[1:] != (4, 4):
        raise ValueError(
            f"ground_truth must have shape (N, 4, 4), got {ground_truth.shape}"
        )
    if estimated.shape[0] != ground_truth.shape[0]:
        raise ValueError(
            f"Trajectory lengths differ: estimated has {estimated.shape[0]} "
            f"poses, ground_truth has {ground_truth.shape[0]} poses"
        )

    n = estimated.shape[0]
    if n < 3:
        raise ValueError(
            f"At least 3 poses are required for ATE computation, got {n}"
        )

    # Extract positions (N, 3)
    est_pos = estimated[:, :3, 3]
    gt_pos = ground_truth[:, :3, 3]

    # Align estimated trajectory to ground truth
    R, t, s = umeyama_alignment(est_pos, gt_pos)
    est_pos_aligned = (s * (R @ est_pos.T)).T + t

    # Per-pose translational errors
    errors = np.linalg.norm(est_pos_aligned - gt_pos, axis=1)

    rmse = float(np.sqrt(np.mean(errors ** 2)))
    mean = float(np.mean(errors))
    median = float(np.median(errors))
    std = float(np.std(errors))
    max_err = float(np.max(errors))

    logger.debug(
        "ATE (n=%d): RMSE=%.4f, mean=%.4f, median=%.4f, std=%.4f, max=%.4f",
        n,
        rmse,
        mean,
        median,
        std,
        max_err,
    )

    return {
        "rmse": rmse,
        "mean": mean,
        "median": median,
        "std": std,
        "max": max_err,
    }


# ---------------------------------------------------------------------------
# Relative Pose Error (RPE)
# ---------------------------------------------------------------------------


def compute_rpe(
    estimated: np.ndarray,
    ground_truth: np.ndarray,
    delta: int = 1,
) -> dict[str, float]:
    """Compute the Relative Pose Error (RPE).

    For every pair of poses separated by *delta* steps, the relative
    transformation is computed for both the estimated and ground-truth
    trajectories.  The translational and rotational components of the
    residual are then aggregated.

    Args:
        estimated: Estimated poses, shape (N, 4, 4).
        ground_truth: Ground-truth poses, shape (N, 4, 4).
        delta: Step size for relative pose computation.  Must be a positive
            integer.

    Returns:
        A dict with keys:

        - ``"trans_rmse"`` – RMSE of translational errors (meters).
        - ``"trans_mean"`` – Mean translational error (meters).
        - ``"rot_rmse"``  – RMSE of rotational errors (degrees).
        - ``"rot_mean"``  – Mean rotational error (degrees).

    Raises:
        ValueError: If inputs are empty, have mismatched lengths, shapes are
            not ``(N, 4, 4)``, or *delta* is not a positive integer.
    """
    estimated = np.asarray(estimated, dtype=np.float64)
    ground_truth = np.asarray(ground_truth, dtype=np.float64)

    # --- input validation ---------------------------------------------------
    if estimated.size == 0 or ground_truth.size == 0:
        raise ValueError("Input pose arrays must not be empty.")

    if estimated.ndim != 3 or estimated.shape[1:] != (4, 4):
        raise ValueError(
            f"estimated must have shape (N, 4, 4), got {estimated.shape}"
        )
    if ground_truth.ndim != 3 or ground_truth.shape[1:] != (4, 4):
        raise ValueError(
            f"ground_truth must have shape (N, 4, 4), got {ground_truth.shape}"
        )
    if estimated.shape[0] != ground_truth.shape[0]:
        raise ValueError(
            f"Trajectory lengths differ: estimated has {estimated.shape[0]} "
            f"poses, ground_truth has {ground_truth.shape[0]} poses"
        )
    if not isinstance(delta, int) or delta < 1:
        raise ValueError(f"delta must be a positive integer, got {delta}")

    n = estimated.shape[0]
    if n <= delta:
        raise ValueError(
            f"Trajectory length ({n}) must be greater than delta ({delta})"
        )

    trans_errors: list[float] = []
    rot_errors: list[float] = []

    for i in range(n - delta):
        # Relative transforms
        # rel_est = est[i]^{-1} @ est[i+delta]
        est_inv = np.linalg.inv(estimated[i])
        gt_inv = np.linalg.inv(ground_truth[i])

        rel_est = est_inv @ estimated[i + delta]
        rel_gt = gt_inv @ ground_truth[i + delta]

        # Error between relative transforms
        t_err, r_err = pose_error(rel_est, rel_gt)
        trans_errors.append(t_err)
        rot_errors.append(r_err)

    trans_errors_arr = np.array(trans_errors)
    rot_errors_arr = np.array(rot_errors)

    result = {
        "trans_rmse": float(np.sqrt(np.mean(trans_errors_arr ** 2))),
        "trans_mean": float(np.mean(trans_errors_arr)),
        "rot_rmse": float(np.sqrt(np.mean(rot_errors_arr ** 2))),
        "rot_mean": float(np.mean(rot_errors_arr)),
    }

    logger.debug(
        "RPE (n=%d, delta=%d): trans_rmse=%.4f, rot_rmse=%.4f deg",
        n,
        delta,
        result["trans_rmse"],
        result["rot_rmse"],
    )

    return result


# ---------------------------------------------------------------------------
# Place Recognition – Recall@K
# ---------------------------------------------------------------------------


def recall_at_k(
    descriptors_query: np.ndarray,
    descriptors_db: np.ndarray,
    positions_query: np.ndarray,
    positions_db: np.ndarray,
    k_values: list[int] | None = None,
    threshold: float = 10.0,
) -> dict[str, float]:
    """Compute Recall@K for place recognition.

    For each query, the *K* nearest database descriptors (by Euclidean
    distance in descriptor space) are retrieved.  A query is considered
    *correctly recognised* if **any** of the top-K retrieved candidates is
    within *threshold* meters of the query's true position.

    Args:
        descriptors_query: Query descriptors, shape (Q, D).
        descriptors_db: Database descriptors, shape (M, D).
        positions_query: Query positions, shape (Q, 2) or (Q, 3).
        positions_db: Database positions, shape (M, 2) or (M, 3).
        k_values: List of K values to evaluate.  Defaults to ``[1, 5, 10]``.
        threshold: Distance threshold in meters for a correct match.

    Returns:
        A dict mapping ``"recall@{k}"`` to the corresponding recall value
        (float in [0, 1]).

    Raises:
        ValueError: If inputs are empty, have mismatched sizes, or descriptor
            dimensions do not match.
    """
    if k_values is None:
        k_values = [1, 5, 10]

    descriptors_query = np.asarray(descriptors_query, dtype=np.float64)
    descriptors_db = np.asarray(descriptors_db, dtype=np.float64)
    positions_query = np.asarray(positions_query, dtype=np.float64)
    positions_db = np.asarray(positions_db, dtype=np.float64)

    # --- input validation ---------------------------------------------------
    if descriptors_query.size == 0 or descriptors_db.size == 0:
        raise ValueError("Descriptor arrays must not be empty.")
    if positions_query.size == 0 or positions_db.size == 0:
        raise ValueError("Position arrays must not be empty.")

    if descriptors_query.ndim != 2 or descriptors_db.ndim != 2:
        raise ValueError(
            "Descriptors must be 2-D arrays (num_samples, descriptor_dim)."
        )
    if descriptors_query.shape[1] != descriptors_db.shape[1]:
        raise ValueError(
            f"Descriptor dimensions differ: query has "
            f"{descriptors_query.shape[1]}, db has {descriptors_db.shape[1]}"
        )
    if descriptors_query.shape[0] != positions_query.shape[0]:
        raise ValueError(
            f"Number of query descriptors ({descriptors_query.shape[0]}) does "
            f"not match number of query positions ({positions_query.shape[0]})"
        )
    if descriptors_db.shape[0] != positions_db.shape[0]:
        raise ValueError(
            f"Number of db descriptors ({descriptors_db.shape[0]}) does not "
            f"match number of db positions ({positions_db.shape[0]})"
        )

    num_queries = descriptors_query.shape[0]
    num_db = descriptors_db.shape[0]

    # Pairwise distances in descriptor space: (Q, M)
    desc_dists = cdist(descriptors_query, descriptors_db, metric="euclidean")

    # Pairwise distances in position space: (Q, M)
    pos_dists = cdist(positions_query, positions_db, metric="euclidean")

    # Sort database indices by descriptor distance for each query
    sorted_indices = np.argsort(desc_dists, axis=1)

    results: dict[str, float] = {}
    max_k = max(k_values)

    for k in k_values:
        effective_k = min(k, num_db)
        correct = 0
        for q in range(num_queries):
            top_k_indices = sorted_indices[q, :effective_k]
            # Check if any retrieved candidate is within threshold
            min_pos_dist = np.min(pos_dists[q, top_k_indices])
            if min_pos_dist <= threshold:
                correct += 1
        recall = correct / num_queries
        results[f"recall@{k}"] = recall

    logger.debug(
        "Recall@K (Q=%d, DB=%d, threshold=%.1f m): %s",
        num_queries,
        num_db,
        threshold,
        ", ".join(f"{k}={v:.4f}" for k, v in results.items()),
    )

    return results


# ---------------------------------------------------------------------------
# Precision-Recall Curve for Loop Closure
# ---------------------------------------------------------------------------


def precision_recall_curve(
    similarities: np.ndarray,
    labels: np.ndarray,
) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """Compute a precision-recall curve for loop closure evaluation.

    Given pairwise similarity scores and binary ground-truth labels, this
    function sweeps over similarity thresholds and computes precision and
    recall at each threshold.

    Args:
        similarities: 1-D array of similarity scores (higher = more similar).
        labels: 1-D binary array of ground-truth labels (1 = true loop
            closure, 0 = negative).

    Returns:
        A tuple ``(precision, recall, thresholds)`` where each element is a
        1-D numpy array.  *precision* and *recall* have the same length as
        *thresholds*.  Thresholds are sorted in descending order so that
        recall is monotonically non-decreasing.

    Raises:
        ValueError: If inputs are empty, have different lengths, or labels
            contain values other than 0 and 1.
    """
    similarities = np.asarray(similarities, dtype=np.float64).ravel()
    labels = np.asarray(labels, dtype=np.float64).ravel()

    # --- input validation ---------------------------------------------------
    if similarities.size == 0:
        raise ValueError("similarities array must not be empty.")
    if labels.size == 0:
        raise ValueError("labels array must not be empty.")
    if similarities.shape[0] != labels.shape[0]:
        raise ValueError(
            f"Length mismatch: similarities has {similarities.shape[0]} "
            f"elements, labels has {labels.shape[0]}"
        )

    unique_labels = np.unique(labels)
    if not np.all(np.isin(unique_labels, [0.0, 1.0])):
        raise ValueError(
            f"labels must contain only 0 and 1, found unique values: "
            f"{unique_labels.tolist()}"
        )

    total_positives = np.sum(labels == 1)
    if total_positives == 0:
        logger.warning(
            "No positive labels found; precision-recall curve is undefined."
        )
        return (
            np.array([], dtype=np.float64),
            np.array([], dtype=np.float64),
            np.array([], dtype=np.float64),
        )

    # Sort by descending similarity
    sorted_indices = np.argsort(-similarities)
    sorted_labels = labels[sorted_indices]
    sorted_similarities = similarities[sorted_indices]

    # Use unique thresholds to avoid redundant computation
    unique_thresholds, first_indices = np.unique(
        sorted_similarities[::-1], return_index=True
    )
    # We want descending thresholds
    unique_thresholds = unique_thresholds[::-1]

    precisions: list[float] = []
    recalls: list[float] = []
    thresholds_out: list[float] = []

    for thresh in unique_thresholds:
        predicted_positive = similarities >= thresh
        tp = np.sum(predicted_positive & (labels == 1))
        fp = np.sum(predicted_positive & (labels == 0))

        precision = tp / (tp + fp) if (tp + fp) > 0 else 1.0
        recall = tp / total_positives

        precisions.append(float(precision))
        recalls.append(float(recall))
        thresholds_out.append(float(thresh))

    precision_arr = np.array(precisions, dtype=np.float64)
    recall_arr = np.array(recalls, dtype=np.float64)
    thresholds_arr = np.array(thresholds_out, dtype=np.float64)

    logger.debug(
        "Precision-recall curve: %d thresholds, %d positives out of %d total",
        len(thresholds_out),
        int(total_positives),
        len(labels),
    )

    return precision_arr, recall_arr, thresholds_arr
