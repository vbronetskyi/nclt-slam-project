{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 02 - Kaggle Training: Place Recognition on NCLT\n\nTrain a MinkLoc3D-based place recognition model on the NCLT dataset.\n\n**Requirements**: Attach both Kaggle datasets to this notebook:\n1. [NCLT Preprocessed](https://www.kaggle.com/datasets/creatorofuniverses/nclt-iprofi-hack-23) — LiDAR point clouds, images, poses\n2. [NCLT Sensors Addon](https://www.kaggle.com/datasets/YOUR_USERNAME/nclt-sensors-addon) — IMU, GPS, odometry, gyro, ground truth"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the project repo (adjust URL)\n",
    "# !git clone https://github.com/YOUR_USERNAME/nclt-slam-project.git\n",
    "# %cd nclt-slam-project\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q torch torchvision open3d pyyaml tqdm scipy scikit-learn matplotlib\n",
    "# MinkowskiEngine requires special installation:\n",
    "# !pip install -q MinkowskiEngine -f https://nvidia.com/MinkowskiEngine/cu118/torch2.0.0/index.html\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Link Kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\n# --- Primary dataset: LiDAR point clouds + poses ---\nKAGGLE_DATA = Path('/kaggle/input/nclt-iprofi-hack-23/NCLT_preprocessed')\nLOCAL_DATA = Path('./data/NCLT_preprocessed')\n\nif KAGGLE_DATA.exists():\n    print(f'Running on Kaggle. LiDAR data at: {KAGGLE_DATA}')\n    LOCAL_DATA.parent.mkdir(parents=True, exist_ok=True)\n    if not LOCAL_DATA.exists():\n        os.symlink(str(KAGGLE_DATA), str(LOCAL_DATA))\n    data_path = KAGGLE_DATA\nelif LOCAL_DATA.exists():\n    print(f'Running locally. LiDAR data at: {LOCAL_DATA}')\n    data_path = LOCAL_DATA\nelse:\n    raise FileNotFoundError(\n        'Dataset not found. On Kaggle, attach the NCLT dataset. '\n        'Locally, run: python scripts/download_nclt_sample.py'\n    )\n\n# --- Sensors addon dataset: IMU, GPS, odometry, gyro, ground truth ---\nKAGGLE_SENSORS = Path('/kaggle/input/nclt-sensors-addon')\nLOCAL_SENSORS = Path('./data/nclt_sensors_addon')\n\nsensors_path = None\nif KAGGLE_SENSORS.exists():\n    print(f'Sensors addon found at: {KAGGLE_SENSORS}')\n    LOCAL_SENSORS.parent.mkdir(parents=True, exist_ok=True)\n    if not LOCAL_SENSORS.exists():\n        os.symlink(str(KAGGLE_SENSORS), str(LOCAL_SENSORS))\n    sensors_path = KAGGLE_SENSORS\nelif LOCAL_SENSORS.exists():\n    print(f'Local sensors data at: {LOCAL_SENSORS}')\n    sensors_path = LOCAL_SENSORS\nelse:\n    print('Sensors addon not found - sensor features will be disabled.')\n    print('Attach nclt-sensors-addon on Kaggle or download locally.')\n\n# List available sessions (directly under data_path, not in sessions/ subdir)\nsessions = sorted([\n    d.name for d in data_path.iterdir()\n    if d.is_dir() and d.name.startswith('20')\n])\nprint(f'\\nLiDAR sessions ({len(sessions)}): {sessions}')\n\nif sensors_path is not None:\n    sensor_sessions = sorted([\n        d.name for d in sensors_path.iterdir()\n        if d.is_dir() and not d.name.startswith('.')\n    ])\n    print(f'Sensor sessions ({len(sensor_sessions)}): {sensor_sessions}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom src.utils.point_cloud import load_velodyne_bin\nfrom src.utils.io_utils import load_config\n\nconfig = load_config('configs/dataset_config.yaml')\n\n# Load a sample point cloud\nsample_session = sessions[0] if sessions else '2012-01-08'\nvelodyne_dir = data_path / sample_session / 'velodyne_data'\n\nif velodyne_dir.exists():\n    bin_files = sorted(velodyne_dir.glob('*.bin'))\n    if bin_files:\n        sample_pc = load_velodyne_bin(bin_files[0])\n        print(f'Sample point cloud: {sample_pc.shape}')\n        print(f'X range: [{sample_pc[:,0].min():.1f}, {sample_pc[:,0].max():.1f}]')\n        print(f'Y range: [{sample_pc[:,1].min():.1f}, {sample_pc[:,1].max():.1f}]')\n        print(f'Z range: [{sample_pc[:,2].min():.1f}, {sample_pc[:,2].max():.1f}]')\n        \n        # Visualize\n        fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n        ax.scatter(sample_pc[:, 0], sample_pc[:, 1], s=0.1, c=sample_pc[:, 2], cmap='viridis')\n        ax.set_xlabel('X (m)')\n        ax.set_ylabel('Y (m)')\n        ax.set_title(f'Sample Point Cloud - {sample_session}')\n        ax.set_aspect('equal')\n        plt.show()\n    else:\n        print('No .bin files found')\nelse:\n    print(f'Velodyne directory not found: {velodyne_dir}')"
  },
  {
   "cell_type": "markdown",
   "source": "## 3b. Sensor Data Overview (Optional)\n\nIf the sensors addon dataset is attached, preview IMU and GPS data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if sensors_path is not None:\n    from src.datasets.sensor_loader import SessionSensorManager\n    from src.utils.io_utils import load_config as _lc\n\n    _cfg = _lc('configs/dataset_config.yaml')\n    _sensor_cfg = _cfg.get('nclt', {}).get('sensors', {})\n\n    session_name = sample_session\n    session_sensor_dir = sensors_path / session_name\n\n    if session_sensor_dir.exists():\n        manager = SessionSensorManager(session_sensor_dir, _sensor_cfg)\n\n        print(f'Session: {session_name}')\n        print(f'  IMU:          {manager.imu is not None}')\n        print(f'  GPS:          {manager.gps is not None}')\n        print(f'  Odometry:     {manager.odometry is not None}')\n        print(f'  KVH gyro:     {manager.kvh is not None}')\n        print(f'  Ground truth: {manager.ground_truth is not None}')\n\n        # Quick IMU preview\n        if manager.imu is not None:\n            imu_data = manager.imu.load()\n            duration_s = (imu_data.timestamps[-1] - imu_data.timestamps[0]) / 1e6\n            print(f'\\n  IMU: {len(imu_data)} samples, {duration_s:.1f} s')\n\n        # Quick GPS preview\n        if manager.gps is not None:\n            gps_data = manager.gps.load()\n            print(f'  GPS: {len(gps_data)} readings')\n    else:\n        print(f'No sensor data for session {session_name}')\nelse:\n    print('Sensors addon not available - skipping sensor overview.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = load_config('configs/train_config.yaml')\n",
    "training = train_config['training']\n",
    "\n",
    "print('Training configuration:')\n",
    "for key, value in training.items():\n",
    "    print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "\n",
    "Train the place recognition model with triplet loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Choose model based on MinkowskiEngine availability\n",
    "try:\n",
    "    import MinkowskiEngine as ME\n",
    "    model_type = 'minkloc3d'\n",
    "    print('MinkowskiEngine available - using MinkLoc3D')\n",
    "except ImportError:\n",
    "    model_type = 'pointnet'\n",
    "    print('MinkowskiEngine not available - falling back to PointNet')\n",
    "\n",
    "from src.models.place_recognition import PlaceRecognitionWrapper, TripletLoss\n",
    "\n",
    "feature_dim = training.get('feature_dim', 256)\n",
    "model = PlaceRecognitionWrapper(\n",
    "    model_type=model_type,\n",
    "    feature_dim=feature_dim,\n",
    ").to(device)\n",
    "\n",
    "loss_fn = TripletLoss(margin=training.get('margin', 0.2))\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=training.get('learning_rate', 1e-3),\n",
    "    weight_decay=training.get('weight_decay', 1e-4),\n",
    ")\n",
    "\n",
    "print(f'Model: {model_type}, feature_dim={feature_dim}')\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement actual training loop\n",
    "# This is a placeholder - fill in after data loading is verified\n",
    "\n",
    "# from src.datasets.nclt_pairs import NCLTPairsDataset, pairs_collate_fn\n",
    "# from src.datasets.transforms import build_transforms\n",
    "#\n",
    "# aug_config = {\n",
    "#     'point_cloud': config['nclt']['point_cloud'],\n",
    "#     'augmentation': training.get('augmentation', {}),\n",
    "# }\n",
    "# train_transform = build_transforms(aug_config, is_train=True)\n",
    "#\n",
    "# train_dataset = NCLTPairsDataset(\n",
    "#     config_path='configs/dataset_config.yaml',\n",
    "#     split='train',\n",
    "#     transform=train_transform,\n",
    "# )\n",
    "#\n",
    "# train_loader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=training.get('batch_size', 32),\n",
    "#     shuffle=True,\n",
    "#     num_workers=2,\n",
    "#     collate_fn=pairs_collate_fn,\n",
    "# )\n",
    "#\n",
    "# epochs = training.get('epochs', 80)\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0.0\n",
    "#     for batch in train_loader:\n",
    "#         anchor_desc = model(batch['anchor'].to(device))\n",
    "#         positive_desc = model(batch['positive'].to(device))\n",
    "#         negative_desc = model(batch['negatives'].to(device))\n",
    "#         loss = loss_fn(anchor_desc, positive_desc, negative_desc)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "#     print(f'Epoch {epoch}: loss={epoch_loss/len(train_loader):.4f}')\n",
    "\n",
    "print('Training loop placeholder - uncomment when data is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.evaluation.metrics import recall_at_k\n",
    "# from src.evaluation.visualization import plot_recall_at_k\n",
    "#\n",
    "# # Extract descriptors for validation set\n",
    "# model.eval()\n",
    "# descriptors = []\n",
    "# positions = []\n",
    "#\n",
    "# with torch.no_grad():\n",
    "#     for batch in val_loader:\n",
    "#         desc = model(batch['anchor'].to(device))\n",
    "#         descriptors.append(desc.cpu().numpy())\n",
    "#         positions.append(batch['anchor_pose'][:, :3, 3].numpy())\n",
    "#\n",
    "# descriptors = np.concatenate(descriptors)\n",
    "# positions = np.concatenate(positions)\n",
    "#\n",
    "# # Compute recall@K\n",
    "# n = len(descriptors)\n",
    "# mid = n // 2\n",
    "# recall = recall_at_k(\n",
    "#     descriptors[:mid], descriptors[mid:],\n",
    "#     positions[:mid], positions[mid:],\n",
    "#     k_values=[1, 5, 10],\n",
    "# )\n",
    "# print(f'Recall: {recall}')\n",
    "# plot_recall_at_k(recall)\n",
    "# plt.show()\n",
    "\n",
    "print('Evaluation placeholder - uncomment after training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Kaggle output\n",
    "import os\n",
    "\n",
    "output_dir = Path('/kaggle/working') if Path('/kaggle/working').exists() else Path('./checkpoints')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# torch.save({\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'config': training,\n",
    "# }, output_dir / 'best_model.pth')\n",
    "# print(f'Model saved to {output_dir / \"best_model.pth\"}')\n",
    "\n",
    "print(f'Checkpoint directory: {output_dir}')\n",
    "print('Uncomment save code after training is implemented')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}